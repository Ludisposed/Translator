{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helper\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = encoder_hidden_units * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape = (None, None), dtype = tf.int32, name = 'encoder_inputs')\n",
    "encoder_inputs_length = tf.placeholder(shape = (None,), dtype = tf.int32, name = 'encoder_inputs_length')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype = tf.int32, name = 'decoder_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype = tf.float32)\n",
    "\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.rnn_cell import LSTMCell, LSTMStateTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cell = LSTMCell(encoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "((encoder_fw_outputs,\n",
    "  encoder_bw_outputs),\n",
    " (encoder_fw_final_state,\n",
    "  encoder_bw_final_state)) = (\n",
    "    tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                    cell_bw=encoder_cell,\n",
    "                                    inputs=encoder_inputs_embedded,\n",
    "                                    sequence_length=encoder_inputs_length,\n",
    "                                    dtype=tf.float32, time_major=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "encoder_final_state_c = tf.concat((encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "encoder_final_state_h = tf.concat((encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "encoder_final_state = LSTMStateTuple(c = encoder_final_state_c, h = encoder_final_state_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = LSTMCell(decoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ecoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_lengths = encoder_inputs_length + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([decoder_hidden_units, vocab_size], -1, 1), dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.Variable(tf.zeros([vocab_size]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert EOS == 1 and PAD == 0\n",
    "\n",
    "eos_time_slice = tf.ones([batch_size], dtype=tf.int32, name='EOS')\n",
    "pad_time_slice = tf.zeros([batch_size], dtype=tf.int32, name='PAD')\n",
    "\n",
    "eos_step_embedded = tf.nn.embedding_lookup(embeddings, eos_time_slice)\n",
    "pad_step_embedded = tf.nn.embedding_lookup(embeddings, pad_time_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn_initial():\n",
    "    initial_elements_finished = (0 >= decoder_lengths)\n",
    "    initial_input = eos_step_embedded\n",
    "    initial_cell_state = encoder_final_state\n",
    "    initial_cell_output = None\n",
    "    initial_loop_state = None\n",
    "    return (initial_elements_finished,\n",
    "            initial_input,\n",
    "            initial_cell_state,\n",
    "            initial_cell_output,\n",
    "            initial_loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn_transition(time, previous_output, previous_state, previous_loop_state):\n",
    "    \n",
    "    def get_next_input():\n",
    "        output_logits = tf.add(tf.matmul(previous_output, W), b)\n",
    "        prediction = tf.argmax(output_logits, axis=1)\n",
    "        next_input = tf.nn.embedding_lookup(embeddings, prediction)\n",
    "        return next_input\n",
    "    \n",
    "    elements_finished = (time >= decoder_lengths)\n",
    "    finished = tf.reduce_all(elements_finished)\n",
    "    input = tf.cond(finished, lambda: pad_step_embedded, get_next_input)\n",
    "    \n",
    "    state = previous_state\n",
    "    output = previous_output\n",
    "    loop_state = None\n",
    "    \n",
    "    return (elements_finished,\n",
    "           input,\n",
    "           state,\n",
    "           output,\n",
    "           loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn(time, previous_output, previous_state, previous_loop_state):\n",
    "    if previous_state is None:\n",
    "        assert previous_output is None and previous_state is None\n",
    "        return loop_fn_initial()\n",
    "    else:\n",
    "        return loop_fn_transition(time, previous_output, previous_state, previous_loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs_ta, decoder_final_state,_ = tf.nn.raw_rnn(decoder_cell, loop_fn)\n",
    "decoder_outputs = decoder_outputs_ta.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 40) dtype=float32>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "decoder_outputs_flat = tf.reshape(decoder_outputs, (-1,decoder_dim))\n",
    "decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
    "decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "#loss function\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "#train it \n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of the batch:\n",
      "[2, 5, 3, 2, 8, 8, 5, 4]\n",
      "[7, 8, 9, 3, 9, 8]\n",
      "[2, 6, 9]\n",
      "[3, 2, 3, 5, 4, 8, 8]\n",
      "[5, 5, 3, 3]\n",
      "[6, 7, 5, 6]\n",
      "[3, 6, 4]\n",
      "[6, 5, 5, 8, 6, 5]\n",
      "[5, 4, 2]\n",
      "[9, 6, 8, 6]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "batches = helper.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "print ('head of the batch:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    encoder_inputs_, encoder_input_lengths_ = helper.batch(batch)\n",
    "    decoder_targets_, _ = helper.batch(\n",
    "        [(sequence) + [EOS] + [PAD] * 2 for sequence in batch]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 0.03901904076337814\n",
      "  sample 1:\n",
      "    input     > [5 5 6 4 7 4 6 0]\n",
      "    predicted > [5 5 6 4 7 4 6 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 4 3 9 5 0 0 0]\n",
      "    predicted > [9 4 3 9 5 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 5 4 2 7 8 8 0]\n",
      "    predicted > [2 5 4 2 7 8 8 1 0 0 0]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.033514827489852905\n",
      "  sample 1:\n",
      "    input     > [5 2 6 9 0 0 0 0]\n",
      "    predicted > [5 2 6 9 1 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [7 3 3 7 3 6 5 9]\n",
      "    predicted > [7 3 3 3 7 6 5 9 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 2 3 0 0 0 0 0]\n",
      "    predicted > [9 2 3 1 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.019277207553386688\n",
      "  sample 1:\n",
      "    input     > [2 9 7 6 0 0 0 0]\n",
      "    predicted > [2 9 7 6 1 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 6 7 4 6 8 2 0]\n",
      "    predicted > [6 6 7 4 6 8 2 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 6 6 3 8 8 7 0]\n",
      "    predicted > [4 6 6 3 8 8 7 1 0 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.018141940236091614\n",
      "  sample 1:\n",
      "    input     > [3 6 5 0 0 0 0 0]\n",
      "    predicted > [3 6 5 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 4 7 4 8 9 4 0]\n",
      "    predicted > [3 4 7 4 8 9 4 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 8 3 0 0 0 0 0]\n",
      "    predicted > [6 8 3 1 0 0 0 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_batches = 3001\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "try:\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0056 after 900600 example (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHuxJREFUeJzt3Xl8VPW9//HXJythC0ICYtgChk1Ewai4L+CCWKm9ti5t\n1dtaatW63NZeW61aq9a2/rxuvfWnqFWvVq31VupO3VckULHsIGGVJWxZIMtk8r1/zCFMyEoyyZkz\n834+HvPgbDnnM8fxPWe+55zvMeccIiKSWFL8LkBERGJP4S4ikoAU7iIiCUjhLiKSgBTuIiIJSOEu\nIpKAFO4iIglI4S4ikoAU7iIiCSjNrw3n5OS4YcOG+bV5EZFAmjdv3lbnXG5ry/kW7sOGDaOoqMiv\nzYuIBJKZrWnLcmqWERFJQAp3EZEEpHAXEUlACncRkQSkcBcRSUAKdxGRBKRwFxFJQIEL92Wbyrn7\njWVsq6j2uxQRkbgVuHBfVVLBg++sZEu5wl1EpDmBC/cemZGbandV1/pciYhI/ApcuGdlpAKwuybs\ncyUiIvErcOGelmIAhOucz5WIiMSvwIV7emqk5FC4zudKRETiV+DCPS01cuReqyN3EZFmBS/cU3Tk\nLiLSmgCGu9rcRURaE7xw39MsE1a4i4g0J3DhXn9CtU7NMiIizQlcuO9pltGRu4hI8wIY7pGSdbWM\niEjzghfu9W3uapYREWlOcMNdR+4iIs0KXLin6zp3EZFWBS7cU1IMM13nLiLSksCFO0SO3kO6WkZE\npFmBDPe0VNMJVRGRFgQz3FNMJ1RFRFoQyHAvq6rlTx+v9rsMEZG4FchwFxGRlincRUQSUKvhbmaD\nzewdM1tsZovM7JomljEzu9/MVprZF2Y2sXPKFRGRtkhrwzK1wE+cc/PNrBcwz8xmO+cWRy0zFSjw\nXkcDf/T+FRERH7R65O6c2+icm+8NlwNLgLx9FpsOPOkiPgX6mNnAmFfryemZAUBNrS6HFBFpyn61\nuZvZMGACMGefWXnAuqjx9TT+AsDMZphZkZkVlZSU7F+lUQ45KBuAkorqdq9DRCSRtTnczawn8Ffg\nWudcWXs25px72DlX6JwrzM3Nbc8qAPjaYQcBENZdqiIiTWpTuJtZOpFgf9o592ITi2wABkeND/Km\ndYqNOysBWL65vLM2ISISaG25WsaAR4Elzrl7mllsFnCxd9XMJKDUObcxhnU28O7ySJPOYx8Vd9Ym\nREQCrS1H7scB3wVONbPPvddZZna5mV3uLfMqsApYCTwCXNE55UZcecoIAE4d3b8zNyMiElitXgrp\nnPsQsFaWccCVsSqqNaMP7A1Az8y2XMkpIpJ8AnmHaveMVAAqQ2GfKxERiU+BDPdu6ZFwX7mlwudK\nRETiUyDDPTMtUvbTc9b6XImISHwKZLhHLuCByTqhKiLSpECG+x5zirf7XYKISFwKdLhXVNf6XYKI\nSFwKdLiLiEjTFO4iIglI4S4ikoACG+6Thvf1uwQRkbgV4HDvB0Bdnbr9FRHZV2DD/dnPIs8G2Vxe\n5XMlIiLxJ7DhflR+pFmmrFKXQ4qI7Cuw4e7dpMrvXl/qbyEiInEosOFeWRPpEXKD91QmERHZK7Dh\nPi4v8pDsof26+1yJiEj8CWy4f2fSUAAOH3yAz5WIiMSfwIZ7t/RI6b9Vm7uISCOBDfeM1MCWLiLS\n6QKbkGleuB9/cI7PlYiIxJ/AhjvAQdndODC7m99liIjEnUCHe2Z6KtW1dX6XISISdwId7hmpKdTU\nhv0uQ0Qk7gQ63FNSjPIqdT8gIrKvNL8L6IglG8v8LkFEJC4F+shdRESaFuhwP+OQAaSY31WIiMSf\nQIf7jt0h6hw4pwd2iIhEC3S4f1a8HYCtFTU+VyIiEl8CHe571NbpWncRkWiBDvdrpxQAEKpVs4yI\nSLRAh3tB/14AVIZ0I5OISLRAh3tWRqT83TW6kUlEJFqgw71HRuQerF3VOnIXEYnWarib2WNmtsXM\nFjYz/2QzKzWzz73XzbEvs2k9u0XCvaJaR+4iItHacuT+J+DMVpb5wDl3uPe6reNltU3PzEi4r9xS\n3lWbFBEJhFbD3Tn3PrC9C2rZbz28cL/7zeU+VyIiEl9i1eZ+jJktMLPXzOyQGK2zVX2y0rtqUyIi\ngRKLXiHnA0OdcxVmdhbwN6CgqQXNbAYwA2DIkCEd3vCeR+3l5/To8LpERBJJh4/cnXNlzrkKb/hV\nIN3MmnywqXPuYedcoXOuMDc3t6ObBmBYv+6MH5Qdk3WJiCSKDoe7mR1oZuYNH+Wtc1tH19tWq7ft\n5qXPv+qqzYmIBEKrzTJm9mfgZCDHzNYDtwDpAM65h4DzgB+ZWS1QCVzg1E2jiIivWg1359yFrcx/\nEHgwZhWJiEiHBfoO1WjqgkBEZK+ECfcdu0N+lyAiEjcSJtzr6tTMLyKyR8KE++sLN/ldgohI3EiY\ncC+rUrOMiMgegQ/3Q/MiNzBt2FHpcyUiIvEj8OFe0L8nAC/+c4PPlYiIxI/Ah3tGWuDfgohIzAU+\nGb915GC/SxARiTuBD/fxeeo0TERkX4EP9z3d/gKoSxsRkYjAh3u0cj1LVUQESLBwT4n0PCwikvQS\nKtw/+bLLupEXEYlrCRXuP3iyyO8SRETiQkKE+zHD+/ldgohIXEmIcJ9x4nC/SxARiSsJEe7HjNCR\nu4hItIQI927pqfXDpXpoh4hIYoR7tBVbyv0uQUTEdwkX7hc+8qnfJYiI+C5hwv2ayQUAhMLqgkBE\nJGHCfczA3n6XICISNxIm3AsG9KwfVgdiIpLsEibch/btXj98+ytLfKxERMR/CRPu0V3/PvphsY+V\niIj4L2HCHeDEkbl+lyAiEhcSKtz7ZKX7XYKISFxIqHC/6Ogh9cOVNWEfKxER8VdChfukqN4hx9z8\nuo+ViIj4K6HCXUREIhTuIiIJKOHC/Ucnj6gf3lRa5WMlIiL+Sbhwv27KyPrhSb95y8dKRET802q4\nm9ljZrbFzBY2M9/M7H4zW2lmX5jZxNiX2XYZaQ3fUk1tnU+ViIj4py1H7n8Czmxh/lSgwHvNAP7Y\n8bI6puimKfXDn67a5mMlIiL+aDXcnXPvA9tbWGQ68KSL+BToY2YDY1Vge+T0zKwfvu65z32sRETE\nH7Foc88D1kWNr/emxYVtu2r8LkFEpMt16QlVM5thZkVmVlRSUtKp25oypn+nrl9EJJ7FItw3AIOj\nxgd50xpxzj3snCt0zhXm5nZuJ18PXLj3vG7x1l2dui0RkXgTi3CfBVzsXTUzCSh1zm2MwXo7JCsj\ntX74lLvfZWtFtY/ViIh0rbZcCvln4BNglJmtN7Pvm9nlZna5t8irwCpgJfAIcEWnVbufbv3a2Prh\nfyze7GMlIiJdy/x6JF1hYaErKirq1G2UVYUYf+ub9eOr75rWqdsTEelsZjbPOVfY2nIJd4dqtN7d\nGvbv/llxS1d0iogkjoQO93196/9/4ncJIiJdIuHDfdntDW+uXbih1KdKRES6TsKHe2ZaaoPxsx/4\n0KdKRES6TsKHO8Azlx3tdwkiIl0qKcL9kLzsBuPrtu/2qRIRka6RFOGendXwqpkTfvcOO9TnjIgk\nsKQId2jcNPPX+et9qkREpPMlTbgfe3BOg/G731zmUyUiIp0vacId4Jjh/eqHq0J11NX5c3euiEhn\nS6pwf+CiCQ3Gz/mDLosUkcSUVOGe0zOTs8fvfUjUwg1lbCyt9LEiEZHOkVThDvDAhQ2P3i9/ap5P\nlYiIdJ6kC3cz45GL93aotmC9uiMQkcSTdOEOcNrYAQ3G31m2xadKREQ6R1KGO0B6qtUP//vjc9lV\nXetjNSIisZW04b7s11MbjB9yyxv49eASEZFYS9pwT0kxJo/u32Dako3lCngRSQhJG+5AgxOrAGfd\n/wFPfrLGp2pERGInqcM9JcUaTbtn9nIfKhERia2kDneAO889tMF4aWXIp0pERGIn6cP9oqOH+F2C\niEjMJX24A9w0bUyD8WE3vMLuGl0aKSLBpXAHLjthOG/95KQG0wpv/4dP1YiIdJzC3TMit2eD8d01\nYZ8qERHpOIV7Cw771Zt+lyAi0i4K9yizrzuxwXhpZYgZTxaxYnO5TxWJiLSPwj1KwYBe/OS0kQ2m\nvbl4M6f91/s+VSQi0j4K9338eHJBk9Of+Hh11xYiItIBCvcmjB3Yu9G0W2Yt4l11DSwiAaFwb8Kr\n15zANybkNZp+6eNzfahGRGT/Kdybcc/5h3PtlMZNND94sohNpVU+VCQi0nYK9xZcO2Vko2mzF2/m\n2zM/9aEaEZG2U7i3Ytr4gY2mfVmyy4dKRETark3hbmZnmtkyM1tpZjc0Mf9SMysxs8+912WxL9Uf\n955/OD0yUhtNv/Lp+RRv3UW4Tg/3EJH402q4m1kq8AdgKjAWuNDMxjax6HPOucO918wY1+mb9NQU\n5tw4pdH0V/61kVPufpej7lAfNCISf9py5H4UsNI5t8o5VwM8C0zv3LLiS8/MNK5rov0dYNuuGrZV\nVHdxRSIiLWtLuOcB66LG13vT9vVvZvaFmb1gZoNjUl0cuerUg5udd8Tt/+CNRZu6sBoRkZbF6oTq\n34FhzrnxwGzgiaYWMrMZZlZkZkUlJSUx2nTXSE0xFv7qjGbn//Cpeazcoj5oRCQ+tCXcNwDRR+KD\nvGn1nHPbnHN72iZmAkc0tSLn3MPOuULnXGFubm576vVVz8y0Fp/cNOWe93lryeYurEhEpGltCfe5\nQIGZ5ZtZBnABMCt6ATOLvl7wHGBJ7EqML3eeeyi3TT+k2fnff6KI8io9h1VE/NVquDvnaoGrgDeI\nhPbzzrlFZnabmZ3jLXa1mS0yswXA1cClnVVwPPjupKE8fumRzc6fvVhH7yLiL3POn+u0CwsLXVFR\nkS/bjpVhN7zS4vy5N04ht1dmF1UjIsnAzOY55wpbW053qHbAzItb3r8//cuCLqpERKQhHbl3UEV1\nLWWVIY696+1ml3l2xiQmDe/XhVWJSKLSkXsX6ZmZxkF9snhzn0f0Rbvg4U8pKdeNTiLSdRTuMTJy\nQC9W3zWt2flHqpsCEelCCvcYe+enJzc77/Kn5gFQFQpTWqnLJUWk86T5XUCiyc/p0ey81xdtanCF\nTUtH+iIiHaEj904wddyBbVpu2A2v8PHKrZ1cjYgkI4V7J/j118dx8TFDuff8w1td9qKZc9hVXdsF\nVYlIMtGlkJ2stDLEYb96s03Lfn7zafTpntHJFYlIkOlSyDiRnZXe5rb1w2+bzZn3vk/pbp1sFZGO\nUbh3kTm/mMwPTxze6nJLN5Vz2G1v8tvXl6q5RkTaTeHeRQb07sbPzxrT5uX/+O6XTLrzLcqqQtzy\n0kKqQuFOrE5EEo3a3LvY5rIqemamccgtb+zX32WkprD8jqmdVJWIBEVb29wV7j6pCoW5760V/PHd\nL/f7bycM6cM/1+7kyzvPIjXFOqE6EYlXCveAqAqFGf3L19v1t90zUrlt+jhyemZw8qj+Ma5MROKR\nrpYJiG7pqTx40YR2/e3umjA//csCLn18Ls8XrSNc588XtYjEH4V7HDh7/EF8eedZHDuiHxccObj1\nP2jCz174ghG/eJUPV+iOVxFR3zJxIzXFeOYHkwDYWFrFe8tL2rWe7zw6B4Di35zFs3PX0T0jlemH\n58WsThEJBoV7HPr9eeP5n0/XcPohB3L2Ax+2ax35P3+1fnjMwN5sLK1ieE4PBvftzi0vLeSJT9Zw\n3wWHc85hB2Gmk7IiiUYnVAOgorqWcft56WRznrnsaC6aOad+/KHvTCQ/pyejDuwVk/WLSOfS1TIJ\nJlznuO+tFSzcUMrbS7fEfP3PzZjEUfl9eeSDVXx30jCyMlJbXL6mto6MNJ2yEelqulomwaSmGP9x\n2kgeu/RIDs3L5vozRsV0/U/PWcuEX8/mzleXMubm11m/YzdvLNrU5LLz1+5g5E2v8X47zwuISOfT\nkXuArSqp4PtPFFG8dVenbeP7x+dz5LC+nFCQQ4/MNHbsqmHCr2cDcFB2N1JSjPeuP0U3U4l0ETXL\nJJmyqhDjb21b18Kxdu/5h/P1CXnMW7OD619YwN+vOp4emTpXL9IZFO5JyDlHSUU1/Xt145d/W8hT\nn67psm2nGOy5h2rswN4s3ljGyz8+nnF52V1Wg0gyULgnuXCdoyoUprbOsWNXDWc/8CEVPnUh/Ncf\nHctf569ne0UNt587jpc+/4pwXR3Txh/EKb9/l1k/Po7RB/b2pTaRoFG4SwNbK6rZuTtEXp8sznvo\nYy48agg3/W2hrzUdNiibBetLufTYYUwbP5CR/Xsxf90OFq4v5ceTC9hdU8vG0ipG5PYEoK7OMfwX\nr/K94/L52Zmj6JYeuaInFK6j4MbX+PnU0fzwpBF+vqVGKmvCPPD2Cq6eXFBfr0hHKNylVZvLqpi/\nZgdLNpYxLi+bK5+ZTygcH/3TfO+4fB77qBiAmRcXctKoXMqrapnoncyFyM1evbqlcfn/zK+f1txT\nr5xzfFVaRV6frM4tfB/3v7WCe2Yv54apo7k8zr54JJgU7tIu7yzbQlVNmKmHDmTYDa/4XU679O6W\nRllVpAnq7PEDKa0M8YHX584lxwzl+jNH03OfE763vLSQl7/YyLxfngZA8dZdDOidSfeMjp0YvuOV\nxTzyQTEzThzOf545WlcVSYcp3KXDKmvCPPz+Kq44ZQTORZ4O9dnqbXy0cpvfpXXYdycNZWtFNa8t\n3MSLVxzLN/77Y2Dvkf+wG15hXF5v/nbFcaSlRm4HqQqFqXOu1cBfuqmMJz5ewx1fH8fwX+ztBuJ7\nx+Vz89fGdtI76nwl5dXk9MxQdxU+U7hLp3DOUbx1F+8tL2H9jkrCdY5xedkUrd7Os3PX+V1eh32r\ncBDPF61vNL1w6AEUrdlRP/78D4/hv99dye7qMEs3lfGNiYP44UnDyUhN4ZwHP2LDzkpeufp4pt3f\nsG+geTdNIS01hfKqEDM/KOamaWPqvzyilVeF6JaeSnoT8wC276phW0U1BQMadhtRvHUX+Tk92vPW\nW7RkYxlT7/uAO889lIuOHhLz9UvbKdzFF39f8BVFq7czon9Pbn5pkd/lBMLIAT0ZdWBvvjExj3ve\nXM6/NpTWz9tzWek1kwtYvrmcW885hLmrt3PVM/8E4MGLJjDogO5kpadyxr3v1//d6rum4ZyjvLqW\nlVsqmDjkAADeXrqZBetKue60kZRXhdhcVsXB/Xtx66xFTBkzgIlD+2AY4259g2smF3D15AIAnpmz\nll/877+YduhA/vDtiW16X1srqumTld7kl1dz1m7bjRkM7tu9zX8TNB3tukPhLnEjXOd4f3kJJ4/K\nZcfuENc+97m6Loixbx89hKfnrK0fv/iYofTvlcndby4H4PVrT+CgPln1N7pF/xI5NC+7wRfKvr64\n9fRGN8itvGMqobDj7Ac+4PozRrF+RyXfOy6flBRjx64aHv94Nfe/tYLcXpkMz+nBb75xKD0y0/hg\nxVYOG5TNw++v4q5/G9/oHMSe8zzRJ8ZnLfiKCYP7MLhvd5xzPDt3HaeNHUB2Vnr9L5td1bVkpqU0\n+CIJ1zm276oht1cmVaEwc4q3c9LI3Bb3Yyhcx6bSqvpt1Tliep7kveUlXPLYZ/zvFccywfvC3V8K\nd4lrzjke/bCY844YRJ/uGQCUVobIzkrHOUdFdS29uqXz+EfFPP7RatZu3w3AHeeOo2j1Dk4fO4Af\nPR25Sqa1cJL4NLRfd165+gQ+XLGViUP78J8vfME7yyJf+nNvnMLijWUs3FDK799YBsCoAb1Ytrm8\n/u/zc3pw5SkHMzC7G9/2ejr9/XnjOe+IQZxy97uUVdWyfVcNZ48fSHZWOk/PWcsrVx/PmAN7UxOu\na3BpaunuEM8XrWPJpjJenL+BO889lAXrdvJc0To+uuFU7n5jGR+s2MpbPzmJ7Kz0Bu/jofe+5K7X\nlnLlKSO4/ozRfLWzkuWby5t89OWtsxbxp49Xc9O0MVx2wvB27TeFuySVULgOA8yM3TW1fGfmHBas\nL+W26Ydw+8tLqAnX+V2ixIm8Plls2FlZPz7z4kIue3L/s+iOc8dx3IgcTr773WaX+eYRg/j9Nw9j\n+eZyTv+vvc1mvzx7LN8/Pn+/twkxDnczOxO4D0gFZjrn7tpnfibwJHAEsA043zm3uqV1KtylK63Y\nXE56agrDcnqwdttuhvTb26ZbG65jY2kVVaEwN7+0iE9WbeORiwv5wZNFdEtPoSqkLwaJrf05d7Gv\nmIW7maUCy4HTgPXAXOBC59ziqGWuAMY75y43swuAc51z57e0XoW7xKOa2jq2VlRzUDM3O9V6vwDS\notp6q2vr6Nsj0rQU3Wvm9WeMYvuuGr5ZOIgeGWksWL+TI4f15YKHP23Uk+fk0f0pr67ls+LtnfXW\nJM40d8Nda9oa7m25Q+MoYKVzbpW34meB6cDiqGWmA7d6wy8AD5qZOb/afETaKSMtpdlgBxpd+dEj\nM40emXvHD+iRQfFvzmryRNyeK0De+enJLdawuayKHplp9TdaOed46fOvOPbgfvTtnsFHX26je0Zq\n5ARiSgpD+nUnIzWF3TW1ZGelE65z7KwM8diHxQzp2515a3YweUx//t+byxk/qA8ff7mVEwpy2FRW\nTX6/7hxfkMsPmmiWyOuTRXqqsamsqtGvl4y0FGpq2/6LJiM1RU1jXawtR+7nAWc65y7zxr8LHO2c\nuypqmYXeMuu98S+9Zbbus64ZwAyAIUOGHLFmTdf1WiginauiurbRnb+14TpCYdfoyV6hcB0pZtQ5\nx/odlQzM7sbO3SH698rEEbmMsqK6llC4jtEH9iZc53h76RZOGplbfxlhVSjM5+t2MuiALMqraimt\nDLFkYxn5OT0orQxx0shctlbUsLWimi3l1WSlp+Kc4/GPVjO0X3fmr93BwOws3ltewri83pxYkMvj\nH62mMhQmKz2VylCYwwb3YUtZFRtLqxrUn5Zi1NY1n53d0lOYMmYAL3+xscn5HblfIJbNMjEL92hq\nlhER2X+xfMzeBmBw1Pggb1qTy5hZGpBN5MSqiIj4oC3hPhcoMLN8M8sALgBm7bPMLOASb/g84G21\nt4uI+KfVE6rOuVozuwp4g8ilkI855xaZ2W1AkXNuFvAo8JSZrQS2E/kCEBERn7SpP1Pn3KvAq/tM\nuzlquAr4ZmxLExGR9mp/7zUiIhK3FO4iIglI4S4ikoAU7iIiCci3XiHNrARo7y2qOUCzN0glIe2P\nhrQ/9tK+aCgR9sdQ51zLHdPjY7h3hJkVteUOrWSh/dGQ9sde2hcNJdP+ULOMiEgCUriLiCSgoIb7\nw34XEGe0PxrS/thL+6KhpNkfgWxzFxGRlgX1yF1ERFoQuHA3szPNbJmZrTSzG/yupzOY2WAze8fM\nFpvZIjO7xpve18xmm9kK798DvOlmZvd7++QLM5sYta5LvOVXmNklzW0zCMws1cz+aWYve+P5ZjbH\ne9/Peb2WYmaZ3vhKb/6wqHX83Ju+zMzO8OeddIyZ9TGzF8xsqZktMbNjkvmzYWbXef+fLDSzP5tZ\nt2T9bDTgnAvMi0ivlF8Cw4EMYAEw1u+6OuF9DgQmesO9iDzDdizwO+AGb/oNwG+94bOA1wADJgFz\nvOl9gVXevwd4wwf4/f46sF/+A3gGeNkbfx64wBt+CPiRN3wF8JA3fAHwnDc81vvMZAL53mcp1e/3\n1Y798ARwmTecAfRJ1s8GkAcUA1lRn4lLk/WzEf0K2pF7/fNcnXM1wJ7nuSYU59xG59x8b7gcWELk\nQzydyP/YeP9+3RueDjzpIj4F+pjZQOAMYLZzbrtzbgcwGzizC99KzJjZIGAaMNMbN+BUIs/shcb7\nY89+egGY7C0/HXjWOVftnCsGVhL5TAWGmWUDJxLpZhvnXI1zbidJ/Nkg0rttlvegoO7ARpLws7Gv\noIV7HrAuany9Ny1heT8bJwBzgAHOuT0PZdwEDPCGm9svibS/7gV+Bux5ynI/YKdzrtYbj35v9e/b\nm1/qLZ8I+yMfKAEe95qoZppZD5L0s+Gc2wDcDawlEuqlwDyS87PRQNDCPamYWU/gr8C1zrmy6Hku\n8lsyKS51MrOzgS3OuXl+1xIH0oCJwB+dcxOAXUSaYeol2WfjACJH3fnAQUAPgvsLJKaCFu5teZ5r\nQjCzdCLB/rRz7kVv8mbvJzXev1u86c3tl0TZX8cB55jZaiJNcacC9xFpYtjzwJno99bcM30TYX+s\nB9Y75+Z44y8QCftk/WxMAYqdcyXOuRDwIpHPSzJ+NhoIWri35Xmugee1AT4KLHHO3RM1K/pZtZcA\nL0VNv9i7MmISUOr9RH8DON3MDvCOcE73pgWKc+7nzrlBzrlhRP6bv+2c+zbwDpFn9kLj/dHUM31n\nARd4V0zkAwXAZ130NmLCObcJWGdmo7xJk4HFJOlng0hzzCQz6+79f7NnfyTdZ6MRv8/o7u+LyNn/\n5UTOZt/odz2d9B6PJ/Kz+gvgc+91FpG2wbeAFcA/gL7e8gb8wdsn/wIKo9b1PSInh1YC/+73e4vB\nvjmZvVfLDCfyP+BK4C9Apje9mze+0ps/POrvb/T20zJgqt/vp5374HCgyPt8/I3I1S5J+9kAfgUs\nBRYCTxG54iUpPxvRL92hKiKSgILWLCMiIm2gcBcRSUAKdxGRBKRwFxFJQAp3EZEEpHAXEUlACncR\nkQSkcBcRSUD/ByJtjtBD2ce4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1109257f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} example (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
