{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helper\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_sentences = helper.read_sentences('data/small_vocab_en')\n",
    "fr_sentences = helper.read_sentences('data/small_vocab_fr')\n",
    "\n",
    "X, Y, en_word2idx, en_idx2word, en_vocab, fr_word2idx, fr_idx2word, fr_vocab = helper.create_dataset(en_sentences, fr_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(fr_vocab)\n",
    "input_embedding_size = vocab_size * 2\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = encoder_hidden_units * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape = (None, None), dtype = tf.int32, name = 'encoder_inputs')\n",
    "encoder_inputs_length = tf.placeholder(shape = (None,), dtype = tf.int32, name = 'encoder_inputs_length')\n",
    "decoder_targets = tf.placeholder(shape = (None, None), dtype = tf.int32, name = 'decoder_targets')\n",
    "decoder_targets_length = encoder_inputs_length = tf.placeholder(shape = (None,), dtype = tf.int32, name = 'encoder_inputs_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype = tf.float32)\n",
    "\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.rnn_cell import LSTMCell, LSTMStateTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_cell = LSTMCell(encoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "((encoder_fw_outputs,\n",
    "  encoder_bw_outputs),\n",
    " (encoder_fw_final_state,\n",
    "  encoder_bw_final_state)) = (\n",
    "    tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                    cell_bw=encoder_cell,\n",
    "                                    inputs=encoder_inputs_embedded,\n",
    "                                    sequence_length=encoder_inputs_length,\n",
    "                                    dtype=tf.float32, time_major=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "encoder_final_state_c = tf.concat((encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "encoder_final_state_h = tf.concat((encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "encoder_final_state = LSTMStateTuple(c = encoder_final_state_c, h = encoder_final_state_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = LSTMCell(decoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ecoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([decoder_hidden_units, vocab_size], -1, 1), dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = tf.Variable(tf.zeros([vocab_size]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eos_time_slice = tf.ones([batch_size], dtype=tf.int32, name='EOS')\n",
    "pad_time_slice = tf.zeros([batch_size], dtype=tf.int32, name='PAD')\n",
    "\n",
    "eos_step_embedded = tf.nn.embedding_lookup(embeddings, eos_time_slice)\n",
    "pad_step_embedded = tf.nn.embedding_lookup(embeddings, pad_time_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn_initial():\n",
    "    initial_elements_finished = (0 >= decoder_targets_length)\n",
    "    initial_input = eos_step_embedded\n",
    "    initial_cell_state = encoder_final_state\n",
    "    initial_cell_output = None\n",
    "    initial_loop_state = None\n",
    "    return (initial_elements_finished,\n",
    "            initial_input,\n",
    "            initial_cell_state,\n",
    "            initial_cell_output,\n",
    "            initial_loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn_transition(time, previous_output, previous_state, previous_loop_state):\n",
    "    \n",
    "    def get_next_input():\n",
    "        output_logits = tf.add(tf.matmul(previous_output, W), b)\n",
    "        prediction = tf.argmax(output_logits, axis=1)\n",
    "        next_input = tf.nn.embedding_lookup(embeddings, prediction)\n",
    "        return next_input\n",
    "    \n",
    "    elements_finished = (time >= decoder_targets_length)\n",
    "    finished = tf.reduce_all(elements_finished)\n",
    "    input = tf.cond(finished, lambda: pad_step_embedded, get_next_input)\n",
    "    \n",
    "    state = previous_state\n",
    "    output = previous_output\n",
    "    loop_state = None\n",
    "    \n",
    "    return (elements_finished,\n",
    "           input,\n",
    "           state,\n",
    "           output,\n",
    "           loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn(time, previous_output, previous_state, previous_loop_state):\n",
    "    if previous_state is None:\n",
    "        assert previous_output is None and previous_state is None\n",
    "        return loop_fn_initial()\n",
    "    else:\n",
    "        return loop_fn_transition(time, previous_output, previous_state, previous_loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_outputs_ta, decoder_final_state,_ = tf.nn.raw_rnn(decoder_cell, loop_fn)\n",
    "decoder_outputs = decoder_outputs_ta.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "decoder_outputs_flat = tf.reshape(decoder_outputs, (-1,decoder_dim))\n",
    "decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
    "decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "learning_rate = 5e-3\n",
    "#loss function\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "#train it \n",
    "train_op = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def c_batch(inputs):\n",
    "    sequence_lengths = [len(seq) for seq in inputs]\n",
    "    batch_size = len(inputs)\n",
    "    \n",
    "    max_sequence_length = max(sequence_lengths)\n",
    "    inputs_batch_major = np.zeros(shape=[batch_size, max_sequence_length], dtype=np.int32) # == PAD\n",
    "    \n",
    "    for i, seq in enumerate(inputs):\n",
    "        for j, element in enumerate(seq):\n",
    "            inputs_batch_major[i, j] = element\n",
    "    inputs_time_major = inputs_batch_major.swapaxes(0, 1)\n",
    "    return inputs_time_major, sequence_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    x = X[:100]\n",
    "    y = Y[:100]\n",
    "    encoder_inputs_, encoder_input_lengths_ = c_batch(x)\n",
    "    decoder_targets_,decoder_targets_length_ = c_batch(y)\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "        decoder_targets_length: decoder_targets_length_\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def c_decode(sequence, idx2word):\n",
    "    sentence = []\n",
    "    for s in sequence:\n",
    "        sentence.append(idx2word[s])\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "batch 0\n",
      "  minibatch loss: 6.114712238311768\n",
      "  sample 1:\n",
      "    input              > [24  3 11 69  6 40  2  9  5  3 11 70  4 36  2]\n",
      "    input              > california is usually quiet during march  and it is usually hot in june \n",
      "    output             > [104   5  16  70   6  48   4  10   7   5  16  25   6  44   4]\n",
      "    output sentence    > california est généralement calme en mars  et il est généralement chaud en juin \n",
      "    predicted          > [ 86 219 178 325  80 243  92 166 170 139 343 262 245  30  52]\n",
      "    predicted sentence > pomme cheval préférés petits raisins voulaient fraise nouveau se visiter redoutée chevaux détendre à juillet\n",
      "  sample 2:\n",
      "    input              > [33 13 15  3  7 86  2  8 32 13  3  7 84  2  0]\n",
      "    input              > his favorite fruit is the orange  but my favorite is the grape  <ukn>\n",
      "    output             > [24 20 21  5 87  4  9 42 21  5 14 85  4  0  0]\n",
      "    output sentence    > son fruit préféré est l'orange  mais mon préféré est le raisin  <ukn> <ukn>\n",
      "    predicted          > [ 27  27 233  29 229 233  54 152 235 301 233 152  93   0   0]\n",
      "    predicted sentence > plus plus vont mois pluie vont novembre vu avez dernière vont vu pêche <ukn> <ukn>\n",
      "  sample 3:\n",
      "    input              > [20  3 68  6 49  2  8  5  3 11 64  4 45  2  0]\n",
      "    input              > paris is relaxing during december  but it is usually chilly in july  <ukn>\n",
      "    output             > [33  5 61  6 55  4  9  7  5 16 23  6 52  4  0]\n",
      "    output sentence    > paris est relaxant en décembre  mais il est généralement froid en juillet  <ukn>\n",
      "    predicted          > [ 90 334  86 129 178  92 316 318 344 125 250 301  75 318   0]\n",
      "    predicted sentence > banane moindres pomme aimons préférés fraise durant plaît qui était -ce dernière oranges plaît <ukn>\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.008818607777357101\n",
      "  sample 1:\n",
      "    input              > [24  3 11 69  6 40  2  9  5  3 11 70  4 36  2]\n",
      "    input              > california is usually quiet during march  and it is usually hot in june \n",
      "    output             > [104   5  16  70   6  48   4  10   7   5  16  25   6  44   4]\n",
      "    output sentence    > california est généralement calme en mars  et il est généralement chaud en juin \n",
      "    predicted          > [104   5  16  70   6  48   4  10   7   5  16  25   6  44   4]\n",
      "    predicted sentence > california est généralement calme en mars  et il est généralement chaud en juin \n",
      "  sample 2:\n",
      "    input              > [33 13 15  3  7 86  2  8 32 13  3  7 84  2  0]\n",
      "    input              > his favorite fruit is the orange  but my favorite is the grape  <ukn>\n",
      "    output             > [24 20 21  5 87  4  9 42 21  5 14 85  4  0  0]\n",
      "    output sentence    > son fruit préféré est l'orange  mais mon préféré est le raisin  <ukn> <ukn>\n",
      "    predicted          > [24 20 21  5 87  4  9 42 21  5 14 85  4  0  0]\n",
      "    predicted sentence > son fruit préféré est l'orange  mais mon préféré est le raisin  <ukn> <ukn>\n",
      "  sample 3:\n",
      "    input              > [20  3 68  6 49  2  8  5  3 11 64  4 45  2  0]\n",
      "    input              > paris is relaxing during december  but it is usually chilly in july  <ukn>\n",
      "    output             > [33  5 61  6 55  4  9  7  5 16 23  6 52  4  0]\n",
      "    output sentence    > paris est relaxant en décembre  mais il est généralement froid en juillet  <ukn>\n",
      "    predicted          > [33  5 61  6 55  4  9  7  5 16 23  6 52  4  0]\n",
      "    predicted sentence > paris est relaxant en décembre  mais il est généralement froid en juillet  <ukn>\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 6.125646905275062e-05\n",
      "  sample 1:\n",
      "    input              > [24  3 11 69  6 40  2  9  5  3 11 70  4 36  2]\n",
      "    input              > california is usually quiet during march  and it is usually hot in june \n",
      "    output             > [104   5  16  70   6  48   4  10   7   5  16  25   6  44   4]\n",
      "    output sentence    > california est généralement calme en mars  et il est généralement chaud en juin \n",
      "    predicted          > [104   5  16  70   6  48   4  10   7   5  16  25   6  44   4]\n",
      "    predicted sentence > california est généralement calme en mars  et il est généralement chaud en juin \n",
      "  sample 2:\n",
      "    input              > [33 13 15  3  7 86  2  8 32 13  3  7 84  2  0]\n",
      "    input              > his favorite fruit is the orange  but my favorite is the grape  <ukn>\n",
      "    output             > [24 20 21  5 87  4  9 42 21  5 14 85  4  0  0]\n",
      "    output sentence    > son fruit préféré est l'orange  mais mon préféré est le raisin  <ukn> <ukn>\n",
      "    predicted          > [24 20 21  5 87  4  9 42 21  5 14 85  4  0  0]\n",
      "    predicted sentence > son fruit préféré est l'orange  mais mon préféré est le raisin  <ukn> <ukn>\n",
      "  sample 3:\n",
      "    input              > [20  3 68  6 49  2  8  5  3 11 64  4 45  2  0]\n",
      "    input              > paris is relaxing during december  but it is usually chilly in july  <ukn>\n",
      "    output             > [33  5 61  6 55  4  9  7  5 16 23  6 52  4  0]\n",
      "    output sentence    > paris est relaxant en décembre  mais il est généralement froid en juillet  <ukn>\n",
      "    predicted          > [33  5 61  6 55  4  9  7  5 16 23  6 52  4  0]\n",
      "    predicted sentence > paris est relaxant en décembre  mais il est généralement froid en juillet  <ukn>\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 2.2207290385267697e-05\n",
      "  sample 1:\n",
      "    input              > [24  3 11 69  6 40  2  9  5  3 11 70  4 36  2]\n",
      "    input              > california is usually quiet during march  and it is usually hot in june \n",
      "    output             > [104   5  16  70   6  48   4  10   7   5  16  25   6  44   4]\n",
      "    output sentence    > california est généralement calme en mars  et il est généralement chaud en juin \n",
      "    predicted          > [104   5  16  70   6  48   4  10   7   5  16  25   6  44   4]\n",
      "    predicted sentence > california est généralement calme en mars  et il est généralement chaud en juin \n",
      "  sample 2:\n",
      "    input              > [33 13 15  3  7 86  2  8 32 13  3  7 84  2  0]\n",
      "    input              > his favorite fruit is the orange  but my favorite is the grape  <ukn>\n",
      "    output             > [24 20 21  5 87  4  9 42 21  5 14 85  4  0  0]\n",
      "    output sentence    > son fruit préféré est l'orange  mais mon préféré est le raisin  <ukn> <ukn>\n",
      "    predicted          > [24 20 21  5 87  4  9 42 21  5 14 85  4  0  0]\n",
      "    predicted sentence > son fruit préféré est l'orange  mais mon préféré est le raisin  <ukn> <ukn>\n",
      "  sample 3:\n",
      "    input              > [20  3 68  6 49  2  8  5  3 11 64  4 45  2  0]\n",
      "    input              > paris is relaxing during december  but it is usually chilly in july  <ukn>\n",
      "    output             > [33  5 61  6 55  4  9  7  5 16 23  6 52  4  0]\n",
      "    output sentence    > paris est relaxant en décembre  mais il est généralement froid en juillet  <ukn>\n",
      "    predicted          > [33  5 61  6 55  4  9  7  5 16 23  6 52  4  0]\n",
      "    predicted sentence > paris est relaxant en décembre  mais il est généralement froid en juillet  <ukn>\n",
      "\n",
      "end training\n"
     ]
    }
   ],
   "source": [
    "max_batches = 3001\n",
    "batches_in_epoch = 1000\n",
    "loss_track = []\n",
    "try:\n",
    "    print('start training')\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp, out, pred) in enumerate(zip(fd[encoder_inputs].T, fd[decoder_targets].T, predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input              > {}'.format(inp))\n",
    "                print('    input              > {}'.format(c_decode(inp, en_idx2word)))\n",
    "                print('    output             > {}'.format(out))\n",
    "                print('    output sentence    > {}'.format(c_decode(out, fr_idx2word)))\n",
    "                print('    predicted          > {}'.format(pred))\n",
    "                print('    predicted sentence > {}'.format(c_decode(pred, fr_idx2word)))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "    print('end training')\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
