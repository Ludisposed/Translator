{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helper\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = encoder_hidden_units * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape = (None, None), dtype = tf.int32, name = 'encoder_inputs')\n",
    "encoder_inputs_length = tf.placeholder(shape = (None,), dtype = tf.int32, name = 'encoder_inputs_length')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype = tf.int32, name = 'decoder_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype = tf.float32)\n",
    "\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.rnn_cell import LSTMCell, LSTMStateTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_cell = LSTMCell(encoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "((encoder_fw_outputs,\n",
    "  encoder_bw_outputs),\n",
    " (encoder_fw_final_state,\n",
    "  encoder_bw_final_state)) = (\n",
    "    tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                    cell_bw=encoder_cell,\n",
    "                                    inputs=encoder_inputs_embedded,\n",
    "                                    sequence_length=encoder_inputs_length,\n",
    "                                    dtype=tf.float32, time_major=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "encoder_final_state_c = tf.concat((encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "encoder_final_state_h = tf.concat((encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "encoder_final_state = LSTMStateTuple(c = encoder_final_state_c, h = encoder_final_state_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = LSTMCell(decoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ecoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_lengths = encoder_inputs_length + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#weight\n",
    "W = tf.Variable(tf.random_uniform([decoder_hidden_units, vocab_size], -1, 1), dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bias\n",
    "b = tf.Variable(tf.zeros([vocab_size]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert EOS == 1 and PAD == 0\n",
    "\n",
    "eos_time_slice = tf.ones([batch_size], dtype=tf.int32, name='EOS')\n",
    "pad_time_slice = tf.zeros([batch_size], dtype=tf.int32, name='PAD')\n",
    "\n",
    "eos_step_embedded = tf.nn.embedding_lookup(embeddings, eos_time_slice)\n",
    "pad_step_embedded = tf.nn.embedding_lookup(embeddings, pad_time_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn_initial():\n",
    "    initial_elements_finished = (0 >= decoder_lengths)\n",
    "    initial_input = eos_step_embedded\n",
    "    initial_cell_state = encoder_final_state\n",
    "    initial_cell_output = None\n",
    "    initial_loop_state = None\n",
    "    return (initial_elements_finished,\n",
    "            initial_input,\n",
    "            initial_cell_state,\n",
    "            initial_cell_output,\n",
    "            initial_loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn_transition(time, previous_output, previous_state, previous_loop_state):\n",
    "    \n",
    "    def get_next_input():\n",
    "        output_logits = tf.add(tf.matmul(previous_output, W), b)\n",
    "        prediction = tf.argmax(output_logits, axis=1)\n",
    "        next_input = tf.nn.embedding_lookup(embeddings, prediction)\n",
    "        return next_input\n",
    "    \n",
    "    elements_finished = (time >= decoder_lengths)\n",
    "    finished = tf.reduce_all(elements_finished)\n",
    "    input = tf.cond(finished, lambda: pad_step_embedded, get_next_input)\n",
    "    \n",
    "    state = previous_state\n",
    "    output = previous_output\n",
    "    loop_state = None\n",
    "    \n",
    "    return (elements_finished,\n",
    "           input,\n",
    "           state,\n",
    "           output,\n",
    "           loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn(time, previous_output, previous_state, previous_loop_state):\n",
    "    if previous_state is None:\n",
    "        assert previous_output is None and previous_state is None\n",
    "        return loop_fn_initial()\n",
    "    else:\n",
    "        return loop_fn_transition(time, previous_output, previous_state, previous_loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#解码始于此\n",
    "decoder_outputs_ta, decoder_final_state,_ = tf.nn.raw_rnn(decoder_cell, loop_fn)\n",
    "decoder_outputs = decoder_outputs_ta.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 40) dtype=float32>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "decoder_outputs_flat = tf.reshape(decoder_outputs, (-1,decoder_dim))\n",
    "decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
    "decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "#loss function\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "#train it \n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of the batch:\n",
      "[6, 7, 4]\n",
      "[6, 4, 6, 5, 9, 3, 4]\n",
      "[5, 6, 8, 2, 8, 2, 6]\n",
      "[7, 8, 8, 5, 9, 5]\n",
      "[3, 2, 4, 4]\n",
      "[8, 5, 4, 5]\n",
      "[4, 3, 3, 2, 8, 2]\n",
      "[9, 5, 3, 8]\n",
      "[8, 4, 2, 4]\n",
      "[5, 4, 9, 2, 3, 5, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "batches = helper.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "print ('head of the batch:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#返回值：输入值（0扩充过），原本的输入值的长度（不含有0的扩充），目标输出（其实就是输入值后面加1和至少两个0）\n",
    "\n",
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    encoder_inputs_, encoder_input_lengths_ = helper.batch(batch)\n",
    "    decoder_targets_, _ = helper.batch(\n",
    "        [(sequence) + [EOS] + [PAD] * 2 for sequence in batch]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.297332763671875\n",
      "  sample 1:\n",
      "    input     > [2 7 6 9 7 0 0 0]\n",
      "    predicted > [5 0 4 7 9 5 7 9 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [7 2 4 0 0 0 0 0]\n",
      "    predicted > [4 1 1 1 1 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 6 4 8 6 9 6 4]\n",
      "    predicted > [6 6 6 1 1 1 1 1 1 1 1]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.5407693386077881\n",
      "  sample 1:\n",
      "    input     > [4 3 8 4 6 4 2 0]\n",
      "    predicted > [4 3 4 6 6 2 4 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [7 5 5 9 4 8 0 0]\n",
      "    predicted > [7 5 5 5 4 8 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 6 8 7 8 0 0 0]\n",
      "    predicted > [9 6 8 8 8 1 0 0 0 0 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.26854103803634644\n",
      "  sample 1:\n",
      "    input     > [3 5 5 0 0 0 0 0]\n",
      "    predicted > [3 5 5 1 0 0 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 5 7 2 3 3 3 7]\n",
      "    predicted > [3 5 7 3 2 3 3 7 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 2 9 4 4 6 7 6]\n",
      "    predicted > [3 2 9 4 4 6 6 6 1 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.1348629742860794\n",
      "  sample 1:\n",
      "    input     > [4 2 2 8 8 5 0 0]\n",
      "    predicted > [4 2 2 8 8 5 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 2 7 8 4 6 2 2]\n",
      "    predicted > [5 2 7 8 6 6 2 2 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 8 7 5 9 3 7 0]\n",
      "    predicted > [4 8 7 5 3 9 7 1 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_batches = 3001\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "try:\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.1354 after 300100 example (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0O0bX6jiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111467e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} example (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
